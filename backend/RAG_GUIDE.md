# ğŸ“š Guia RAG (Retrieval-Augmented Generation)

## O que Ã© RAG?

RAG permite que o ChatGPT responda com base em documentos que vocÃª fornece, tornando as respostas mais precisas e contextualizadas.

## âš¡ Armazenamento 100% Local

**Tudo fica no seu projeto:**
- âœ… PDFs salvos em: `backend/storage/pdfs/`
- âœ… Embeddings em: `backend/storage/chroma_db/`
- âœ… Metadados no MongoDB
- âœ… Sem dependÃªncias de serviÃ§os externos (exceto OpenAI para embeddings)

## Fluxo de Funcionamento

```
1. UsuÃ¡rio faz upload de PDF
2. PDF Ã© salvo em backend/storage/pdfs/{user_id}/
3. Sistema extrai texto do PDF
4. Texto Ã© dividido em chunks (pedaÃ§os)
5. Cada chunk gera um embedding (vetor via OpenAI)
6. Embeddings sÃ£o armazenados em backend/storage/chroma_db/ (arquivo local)
7. Quando usuÃ¡rio pergunta algo:
   - Sistema busca chunks mais relevantes no ChromaDB local
   - Chunks sÃ£o enviados como contexto para ChatGPT
   - ChatGPT responde baseado no contexto do PDF
```

## Como Usar

### 1. Upload de PDF

**Endpoint:** `POST /api/documents/upload`

```bash
curl -X POST "http://localhost:8000/api/documents/upload" \
  -H "Authorization: Bearer {seu_token}" \
  -F "file=@documento.pdf" \
  -F "conversation_id=abc123"
```

**Resposta:**
```json
{
  "filename": "documento.pdf",
  "total_pages": 10,
  "total_chunks": 25,
  "collection_name": "user_123_abc123",
  "status": "success"
}
```

### 2. Chat com RAG

O RAG funciona automaticamente! Quando vocÃª:
- Faz upload de um PDF em uma conversa
- Faz uma pergunta nessa conversa
- O sistema busca automaticamente contexto relevante no PDF
- ChatGPT responde usando esse contexto

**Exemplo:**

```
1. Upload: "manual_produto.pdf"
2. Pergunta: "Qual a garantia do produto?"
3. Sistema busca no PDF: encontra seÃ§Ã£o sobre garantia
4. ChatGPT responde: "Segundo o manual, a garantia Ã© de 12 meses..."
```

### 3. Listar Documentos

**Endpoint:** `GET /api/documents/list`

```bash
curl "http://localhost:8000/api/documents/list?conversation_id=abc123" \
  -H "Authorization: Bearer {seu_token}"
```

### 4. Excluir Documento

**Endpoint:** `DELETE /api/documents/{document_id}`

```bash
curl -X DELETE "http://localhost:8000/api/documents/doc123" \
  -H "Authorization: Bearer {seu_token}"
```

## ğŸ“ Estrutura de Armazenamento Local

```
backend/
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ pdfs/                    # PDFs salvos
â”‚   â”‚   â”œâ”€â”€ user_123/           # Por usuÃ¡rio
â”‚   â”‚   â”‚   â”œâ”€â”€ abc12345_documento1.pdf
â”‚   â”‚   â”‚   â””â”€â”€ def67890_manual.pdf
â”‚   â”‚   â””â”€â”€ user_456/
â”‚   â”‚       â””â”€â”€ xyz98765_relatorio.pdf
â”‚   â””â”€â”€ chroma_db/              # Embeddings (ChromaDB)
â”‚       â”œâ”€â”€ chroma.sqlite3      # Banco local
â”‚       â””â”€â”€ ...                 # Arquivos do ChromaDB
â”œâ”€â”€ .gitignore                  # storage/ estÃ¡ no .gitignore
â””â”€â”€ ...
```

**Importante:** A pasta `storage/` Ã© ignorada pelo git para nÃ£o versionar PDFs e embeddings.

## ConfiguraÃ§Ãµes

### ParÃ¢metros AjustÃ¡veis

No arquivo `services/rag_service.py`:

```python
# Tamanho dos chunks
chunk_size=1000  # Maior = mais contexto, mas menos preciso
chunk_overlap=200  # SobreposiÃ§Ã£o entre chunks

# NÃºmero de chunks retornados
k=3  # Quantos trechos relevantes usar
```

### Caminhos Locais

Tudo Ã© armazenado em:
```python
backend/storage/pdfs/         # Arquivos PDF
backend/storage/chroma_db/    # Embeddings persistentes
```

## LimitaÃ§Ãµes

- **Tamanho mÃ¡ximo:** 10MB por PDF
- **Formato suportado:** Apenas PDF
- **Idioma:** Funciona melhor em inglÃªs, mas portuguÃªs tambÃ©m funciona
- **Custo:** Cada busca usa embeddings da OpenAI (muito barato ~$0.0001/1K tokens)

## Melhorias Futuras

- [ ] Suporte para DOCX, TXT
- [ ] Upload mÃºltiplo
- [ ] Visualizar trechos usados no chat
- [ ] Cache de embeddings
- [ ] Suporte para imagens em PDFs (OCR)

## Troubleshooting

### "Erro ao processar PDF"
- Verifique se o PDF nÃ£o estÃ¡ corrompido
- Tente com um PDF mais simples primeiro

### "Sem resultados relevantes"
- Aumente o valor de `k` para buscar mais chunks
- Refine sua pergunta para ser mais especÃ­fica

### "Resposta nÃ£o usa o contexto"
- Verifique se o PDF foi processado corretamente
- Confirme que estÃ¡ usando a mesma `conversation_id`

